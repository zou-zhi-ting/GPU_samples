// CUDA runtime 库 + CUBLAS 库   
#include "cuda_runtime.h"  
#include "cublas_v2.h"  
#include "book.h"
#include <stdio.h>  
#include <device_launch_parameters.h>
#define N 10
using namespace std;
__global__ void add(int *a, int *b, int *c) {
	int tid = blockIdx.x;       //blockIdx是内置变量，在CUDA运行时已经预先定义了。
	                            //第一个线程块的blockIdx.x为0，最后一个线程块blockIdx.x为N-1。
	if (tid < N)
		c[tid] = a[tid] + b[tid];
}
int main()
{
	int a[N], b[N], c[N];
	int *dev_a, *dev_b, *dev_c;
	//在GPU上分配内存
	HANDLE_ERROR(cudaMalloc((void**)&dev_a, N * sizeof(int)));
	HANDLE_ERROR(cudaMalloc((void**)&dev_b, N * sizeof(int)));
	HANDLE_ERROR(cudaMalloc((void**)&dev_c, N * sizeof(int)));
	//在CPU上为‘a’、‘b’赋值
	for (int i = 0; i < N; i++)
	{
		a[i] = -i;
		b[i] = i*i;
	}

	//将数组‘a’、‘b’复制到GPU
	HANDLE_ERROR(cudaMemcpy(dev_a, a, N * sizeof(int),cudaMemcpyHostToDevice));
	HANDLE_ERROR(cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice));

	add <<<N, 1 >>> (dev_a, dev_b, dev_c); //第一个值N：表示该设备执行核函数时，使用并行线程块的数量为N。
	                                       //第二个值1：表示并行线程数量为1。

	//将数组‘c’从GPU复制到CPU
	HANDLE_ERROR(cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));
	for (int i = 0; i < N; i++)
		printf("%d+%d=%d\n", a[i], b[i], c[i]);
	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);

	system("pause");
	return 0;
}
